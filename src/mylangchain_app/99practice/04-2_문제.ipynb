{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8acaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import MessagesState\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7f68f",
   "metadata": {},
   "source": [
    "#### ë¬¸ì œ 4-2 : ì¡°ê±´ë¶€ ë¶„ê¸°ê°€ ìˆëŠ” ë©”ë‰´ ì¶”ì²œ ì‹œìŠ¤í…œ ( LangGraph ì‚¬ìš©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b1a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¹´í˜ ë©”ë‰´ ë²¡í„° DB ë¡œë”© ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 1. ë²¡í„° DB ë¡œë“œ\n",
    "# ì´ì „ ë¬¸ì œì—ì„œ ìƒì„±í•œ FAISS ë²¡í„° DBë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "if not os.path.exists(\"../db/cafe_db\"):\n",
    "    raise FileNotFoundError(\"Cafe DB not found. Please run the previous notebook (4-1) to create it.\")\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "cafe_db = FAISS.load_local(\n",
    "    \"../db/cafe_db\", \n",
    "    embeddings_model, \n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "\n",
    "print(\"ì¹´í˜ ë©”ë‰´ ë²¡í„° DB ë¡œë”© ì™„ë£Œ!\")\n",
    "\n",
    "# 2. ê³ ê¸‰ ì •ë³´ ì¶”ì¶œ í•¨ìˆ˜ (ìš”êµ¬ì‚¬í•­)\n",
    "def extract_menu_info(doc: Document) -> dict:\n",
    "    \"\"\"Vector DB ë¬¸ì„œì—ì„œ êµ¬ì¡°í™”ëœ ë©”ë‰´ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "    content = doc.page_content\n",
    "    menu_name = doc.metadata.get('menu_name', 'Unknown')\n",
    "    \n",
    "    # ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ê°€ê²©, ì„¤ëª… ë“± ì¶”ì¶œ\n",
    "    price_match = re.search(r'ê°€ê²©:\\s*(â‚©[\\d,]+)', content)\n",
    "    description_match = re.search(r'ì„¤ëª…:\\s*(.+)', content, re.DOTALL)\n",
    "    \n",
    "    return {\n",
    "        \"name\": menu_name,\n",
    "        \"price\": price_match.group(1) if price_match else \"ê°€ê²© ì •ë³´ ì—†ìŒ\",\n",
    "        \"description\": description_match.group(1).strip() if description_match else \"ì„¤ëª… ì—†ìŒ\"\n",
    "    }\n",
    "\n",
    "# 3. ë¬¸ì˜ ìœ í˜• ë¶„ë¥˜ í•¨ìˆ˜\n",
    "def classify_question(user_message: str) -> Literal[\"price\", \"recommendation\", \"menu\", \"general\"]:\n",
    "    \"\"\"í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ì ë¬¸ì˜ ìœ í˜•ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    if any(keyword in user_message for keyword in [\"ê°€ê²©\", \"ì–¼ë§ˆ\"]):\n",
    "        return \"price\"\n",
    "    elif any(keyword in user_message for keyword in [\"ì¶”ì²œ\", \"ë­ê°€ ë§›ìˆì–´\", \"ì¸ê¸°\"]):\n",
    "        return \"recommendation\"\n",
    "    elif len(user_message.split()) < 3 and (\"ì•ˆë…•\" in user_message or \"hi\" in user_message):\n",
    "        return \"general\"\n",
    "    else:\n",
    "        return \"menu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f30d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_menu_inquiry(state: MessagesState) -> dict:\n",
    "    \"\"\"íŠ¹ì • ë©”ë‰´ì— ëŒ€í•œ ë¬¸ì˜ë¥¼ ì²˜ë¦¬í•˜ê³  ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì§ì ‘ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©í•˜ì—¬ ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ìˆ˜í–‰\n",
    "    docs = cafe_db.similarity_search(user_message, k=2)\n",
    "    \n",
    "    if not docs:\n",
    "        response_text = \"ì£„ì†¡í•©ë‹ˆë‹¤, ìš”ì²­í•˜ì‹  ë©”ë‰´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "    else:\n",
    "        info_list = [extract_menu_info(doc) for doc in docs]\n",
    "        response_text = \"ìš”ì²­í•˜ì‹  ë©”ë‰´ ì •ë³´ì…ë‹ˆë‹¤:\\n\\n\"\n",
    "        for info in info_list:\n",
    "            response_text += f\"**- ë©”ë‰´:** {info['name']}\\n\"\n",
    "            response_text += f\"  **- ê°€ê²©:** {info['price']}\\n\"\n",
    "            response_text += f\"  **- ì„¤ëª…:** {info['description']}\\n\\n\"\n",
    "            \n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "def handle_price_inquiry(state: MessagesState) -> dict:\n",
    "    \"\"\"ë©”ë‰´ ê°€ê²©ì— ëŒ€í•œ ë¬¸ì˜ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    # 'ê°€ê²©'ê³¼ ê´€ë ¨ëœ ì¼ë°˜ì ì¸ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•˜ì—¬ ì—¬ëŸ¬ ë©”ë‰´ì˜ ê°€ê²©ì„ ë³´ì—¬ì¤Œ\n",
    "    docs = cafe_db.similarity_search(\"ë©”ë‰´ ê°€ê²©\", k=5)\n",
    "    info_list = [extract_menu_info(doc) for doc in docs]\n",
    "    \n",
    "    response_text = \"ì£¼ìš” ë©”ë‰´ì˜ ê°€ê²© ì •ë³´ì…ë‹ˆë‹¤:\\n\"\n",
    "    for info in info_list:\n",
    "        response_text += f\"- {info['name']}: {info['price']}\\n\"\n",
    "        \n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "def handle_recommendation(state: MessagesState) -> dict:\n",
    "    \"\"\"ë©”ë‰´ ì¶”ì²œ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    # ë¨¼ì € ì‚¬ìš©ì ë©”ì‹œì§€ë¡œ ê²€ìƒ‰ ì‹œë„\n",
    "    docs = cafe_db.similarity_search(user_message, k=3)\n",
    "    \n",
    "    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ 'ì¸ê¸° ë©”ë‰´'ë¡œ ë‹¤ì‹œ ê²€ìƒ‰\n",
    "    if not docs:\n",
    "        docs = cafe_db.similarity_search(\"ì¸ê¸° ë©”ë‰´\", k=3)\n",
    "    \n",
    "    info_list = [extract_menu_info(doc) for doc in docs]\n",
    "    \n",
    "    response_text = \"ì´ëŸ° ë©”ë‰´ëŠ” ì–´ë– ì„¸ìš”? ğŸ˜‹\\n\\n\"\n",
    "    for info in info_list:\n",
    "        response_text += f\"**- ë©”ë‰´:** {info['name']}\\n\"\n",
    "        response_text += f\"  **- ì„¤ëª…:** {info['description']}\\n\\n\"\n",
    "        \n",
    "    return {\"messages\": [AIMessage(content=response_text)]}\n",
    "\n",
    "def handle_general_inquiry(state: MessagesState) -> dict:\n",
    "    \"\"\"ì¼ë°˜ì ì¸ ì¸ì‚¬ë‚˜ ê´€ë ¨ ì—†ëŠ” ë¬¸ì˜ì— ì‘ë‹µí•©ë‹ˆë‹¤.\"\"\"\n",
    "    response_text = \"ì•ˆë…•í•˜ì„¸ìš”! ì €í¬ ì¹´í˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ë©”ë‰´, ê°€ê²©, ì¶”ì²œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š\"\n",
    "    return {\"messages\": [AIMessage(content=response_text)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7b47389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangGraphê°€ ì„±ê³µì ìœ¼ë¡œ ì»´íŒŒì¼ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ë¼ìš°íŒ… í•¨ìˆ˜: ìƒíƒœë¥¼ ë°›ì•„ ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œì˜ ì´ë¦„ì„ ë°˜í™˜\n",
    "def route_message(state: MessagesState):\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "    classification = classify_question(user_message)\n",
    "    \n",
    "    if classification == \"price\":\n",
    "        return \"price_inquiry\"\n",
    "    elif classification == \"recommendation\":\n",
    "        return \"recommendation\"\n",
    "    elif classification == \"menu\":\n",
    "        return \"menu_inquiry\"\n",
    "    else:\n",
    "        return \"general_inquiry\"\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë” ì´ˆê¸°í™”\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "builder.add_node(\"menu_inquiry\", handle_menu_inquiry)\n",
    "builder.add_node(\"price_inquiry\", handle_price_inquiry)\n",
    "builder.add_node(\"recommendation\", handle_recommendation)\n",
    "builder.add_node(\"general_inquiry\", handle_general_inquiry)\n",
    "\n",
    "# ì§„ì…ì (START)ì—ì„œ ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì„¤ì •\n",
    "builder.add_conditional_edges(\n",
    "    START,\n",
    "    route_message,\n",
    "    {\n",
    "        \"menu_inquiry\": \"menu_inquiry\",\n",
    "        \"price_inquiry\": \"price_inquiry\",\n",
    "        \"recommendation\": \"recommendation\",\n",
    "        \"general_inquiry\": \"general_inquiry\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# ê° ë…¸ë“œ ì‹¤í–‰ í›„ì—ëŠ” ê·¸ë˜í”„ ì¢…ë£Œ(END)\n",
    "builder.add_edge(\"menu_inquiry\", END)\n",
    "builder.add_edge(\"price_inquiry\", END)\n",
    "builder.add_edge(\"recommendation\", END)\n",
    "builder.add_edge(\"general_inquiry\", END)\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = builder.compile()\n",
    "\n",
    "print(\"LangGraphê°€ ì„±ê³µì ìœ¼ë¡œ ì»´íŒŒì¼ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5031c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== [Test 1: íŠ¹ì • ë©”ë‰´ ë¬¸ì˜] =====\n",
      "('ìš”ì²­í•˜ì‹  ë©”ë‰´ ì •ë³´ì…ë‹ˆë‹¤:\\n'\n",
      " '\\n'\n",
      " '**- ë©”ë‰´:** ì¹´í˜ë¼ë–¼\\n'\n",
      " '  **- ê°€ê²©:** â‚©5,500\\n'\n",
      " '  **- ì„¤ëª…:** ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ë¶€ë“œëŸ½ê²Œ ìŠ¤íŒ€í•œ ìš°ìœ ë¥¼ ë„£ì–´ ë§Œë“  ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ì…ë‹ˆë‹¤. í¬ë¦¬ë¯¸í•œ ì§ˆê°ê³¼ ë¶€ë“œëŸ¬ìš´ ë§›ì´ '\n",
      " 'íŠ¹ì§•ì´ë©°, ë‹¤ì–‘í•œ ì‹œëŸ½ê³¼ í† í•‘ ì¶”ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¼ë–¼ ì•„íŠ¸ë¡œ ì‹œê°ì  ì¦ê±°ì›€ë„ ì œê³µí•©ë‹ˆë‹¤.\\n'\n",
      " '\\n'\n",
      " '**- ë©”ë‰´:** í”„ë¼í‘¸ì¹˜ë…¸\\n'\n",
      " '  **- ê°€ê²©:** â‚©7,000\\n'\n",
      " '  **- ì„¤ëª…:** ì—ìŠ¤í”„ë ˆì†Œì™€ ìš°ìœ , ì–¼ìŒì„ ë¸”ë Œë”ì— ê°ˆì•„ ë§Œë“  ì‹œì›í•œ ìŒë£Œì…ë‹ˆë‹¤. ë¶€ë“œëŸ½ê³  í¬ë¦¬ë¯¸í•œ ì§ˆê°ì´ íŠ¹ì§•ì´ë©°, íœ˜í•‘í¬ë¦¼ì„ '\n",
      " 'ì˜¬ë ¤ ë‹¬ì½¤í•¨ì„ ë”í–ˆìŠµë‹ˆë‹¤. ì—¬ë¦„ì²  ì¸ê¸° ë©”ë‰´ì…ë‹ˆë‹¤.\\n'\n",
      " '\\n')\n",
      "\n",
      "==============================\n",
      "\n",
      "===== [Test 2: ê°€ê²© ë¬¸ì˜] =====\n",
      "('ì£¼ìš” ë©”ë‰´ì˜ ê°€ê²© ì •ë³´ì…ë‹ˆë‹¤:\\n'\n",
      " '- ë…¹ì°¨ ë¼ë–¼: â‚©5,800\\n'\n",
      " '- ë°”ë‹ë¼ ë¼ë–¼: â‚©6,000\\n'\n",
      " '- í”„ë¼í‘¸ì¹˜ë…¸: â‚©7,000\\n'\n",
      " '- ì¹´í˜ë¼ë–¼: â‚©5,500\\n'\n",
      " '- í‹°ë¼ë¯¸ìˆ˜: â‚©7,500\\n')\n",
      "\n",
      "==============================\n",
      "\n",
      "===== [Test 3: ì¶”ì²œ ìš”ì²­] =====\n",
      "('ì´ëŸ° ë©”ë‰´ëŠ” ì–´ë– ì„¸ìš”? ğŸ˜‹\\n'\n",
      " '\\n'\n",
      " '**- ë©”ë‰´:** í‹°ë¼ë¯¸ìˆ˜\\n'\n",
      " '  **- ì„¤ëª…:** ì´íƒˆë¦¬ì•„ ì „í†µ ë””ì €íŠ¸ë¡œ ë§ˆìŠ¤ì¹´í¬ë„¤ ì¹˜ì¦ˆì™€ ì—ìŠ¤í”„ë ˆì†Œì— ì ì‹  ë ˆì´ë””í•‘ê±°ë¥¼ ì¸µì¸µì´ ìŒ“ì•„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ë¶€ë“œëŸ½ê³  ë‹¬ì½¤í•œ '\n",
      " 'ë§›ì´ íŠ¹ì§•ì´ë©°, ì½”ì½”ì•„ íŒŒìš°ë”ë¡œ ë§ˆë¬´ë¦¬í•˜ì—¬ ê¹Šì€ í’ë¯¸ë¥¼ ìë‘í•©ë‹ˆë‹¤.\\n'\n",
      " '\\n'\n",
      " '**- ë©”ë‰´:** ì•„ì´ìŠ¤ ì•„ë©”ë¦¬ì¹´ë…¸\\n'\n",
      " '  **- ì„¤ëª…:** ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ì°¨ê°€ìš´ ë¬¼ê³¼ ì–¼ìŒì„ ë„£ì–´ ë§Œë“  ì‹œì›í•œ ì•„ì´ìŠ¤ ì»¤í”¼ì…ë‹ˆë‹¤. ê¹”ë”í•˜ê³  ì‹œì›í•œ ë§›ì´ íŠ¹ì§•ì´ë©°, ì›ë‘ '\n",
      " 'ë³¸ì—°ì˜ í’ë¯¸ë¥¼ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”ìš´ ë‚ ì”¨ì— ì¸ê¸°ê°€ ë†’ìŠµë‹ˆë‹¤.\\n'\n",
      " '\\n'\n",
      " '**- ë©”ë‰´:** ì¹´í˜ë¼ë–¼\\n'\n",
      " '  **- ì„¤ëª…:** ì§„í•œ ì—ìŠ¤í”„ë ˆì†Œì— ë¶€ë“œëŸ½ê²Œ ìŠ¤íŒ€í•œ ìš°ìœ ë¥¼ ë„£ì–´ ë§Œë“  ëŒ€í‘œì ì¸ ë°€í¬ ì»¤í”¼ì…ë‹ˆë‹¤. í¬ë¦¬ë¯¸í•œ ì§ˆê°ê³¼ ë¶€ë“œëŸ¬ìš´ ë§›ì´ '\n",
      " 'íŠ¹ì§•ì´ë©°, ë‹¤ì–‘í•œ ì‹œëŸ½ê³¼ í† í•‘ ì¶”ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë¼ë–¼ ì•„íŠ¸ë¡œ ì‹œê°ì  ì¦ê±°ì›€ë„ ì œê³µí•©ë‹ˆë‹¤.\\n'\n",
      " '\\n')\n",
      "\n",
      "==============================\n",
      "\n",
      "===== [Test 4: ì¼ë°˜ ì¸ì‚¬] =====\n",
      "'ì•ˆë…•í•˜ì„¸ìš”! ì €í¬ ì¹´í˜ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤. ë©”ë‰´, ê°€ê²©, ì¶”ì²œì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ˜Š'\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ 1: íŠ¹ì • ë©”ë‰´ ë¬¸ì˜ ---\n",
    "print(\"===== [Test 1: íŠ¹ì • ë©”ë‰´ ë¬¸ì˜] =====\")\n",
    "# ì…ë ¥ í˜•ì‹ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ìˆ˜ì •\n",
    "inputs = {\"messages\": [HumanMessage(content=\"í¬ë¡œí¬ë¬´ìŠˆì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\")]}\n",
    "# ê·¸ë˜í”„ í˜¸ì¶œ\n",
    "response = graph.invoke(inputs)\n",
    "# ì¶œë ¥ í˜•ì‹ë„ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ 'messages' í‚¤ë¡œ ì ‘ê·¼\n",
    "pprint(response[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ 2: ê°€ê²© ë¬¸ì˜ ---\n",
    "print(\"===== [Test 2: ê°€ê²© ë¬¸ì˜] =====\")\n",
    "# ì…ë ¥ í˜•ì‹ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ìˆ˜ì •\n",
    "inputs = {\"messages\": [HumanMessage(content=\"ì»¤í”¼ ê°€ê²©ì´ ê¶ê¸ˆí•´ìš”\")]}\n",
    "response = graph.invoke(inputs)\n",
    "# ì¶œë ¥ í˜•ì‹ë„ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ 'messages' í‚¤ë¡œ ì ‘ê·¼\n",
    "pprint(response[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ 3: ì¶”ì²œ ìš”ì²­ ---\n",
    "print(\"===== [Test 3: ì¶”ì²œ ìš”ì²­] =====\")\n",
    "# ì…ë ¥ í˜•ì‹ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ìˆ˜ì •\n",
    "inputs = {\"messages\": [HumanMessage(content=\"ë‹¬ì½¤í•œ ì¼€ì´í¬ ì¶”ì²œí•´ì¤˜\")]}\n",
    "response = graph.invoke(inputs)\n",
    "# ì¶œë ¥ í˜•ì‹ë„ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ 'messages' í‚¤ë¡œ ì ‘ê·¼\n",
    "pprint(response[\"messages\"][-1].content)\n",
    "print(\"\\n\" + \"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- í…ŒìŠ¤íŠ¸ 4: ì¼ë°˜ ì¸ì‚¬ ---\n",
    "print(\"===== [Test 4: ì¼ë°˜ ì¸ì‚¬] =====\")\n",
    "# ì…ë ¥ í˜•ì‹ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ìˆ˜ì •\n",
    "inputs = {\"messages\": [HumanMessage(content=\"ì•ˆë…•!\")]}\n",
    "response = graph.invoke(inputs)\n",
    "# ì¶œë ¥ í˜•ì‹ë„ ë”•ì…”ë„ˆë¦¬ì´ë¯€ë¡œ 'messages' í‚¤ë¡œ ì ‘ê·¼\n",
    "pprint(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
