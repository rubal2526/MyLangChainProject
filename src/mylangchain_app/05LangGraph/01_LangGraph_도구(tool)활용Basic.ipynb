{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph에서 도구(tool) 활용 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도구(tool)를 활용한 에이전트 개발 방법을 알아봅니다\n",
    "- workflow를 직접 선언하지 않고, 사용가능한 도구들을 전달하면, 에이전트가 적합한 도구를 판단해서 사용합니다\n",
    "    - 이번 회차에서는 `ToolNode`를 통해 도구를 활용하는 방법을 알아봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk\n",
      "5L\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeong\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.13\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000027AB995A510> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027AB995AF90> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LangGraph는 `ToolNode`를 통해 도구를 활용합니다\n",
    "- `ToolNode`의 `invoke()`결과는 도구의 `invoke()` 결과와 유사합니다\n",
    "    - 도구는 도구의 실행 결과를 리턴하고, `ToolNode`는 도구의 실행 결과를 포함한 `ToolMessage`를 리턴합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "tools(tags=None, recurse=True, explode_args=False, func_accepts={'config': ('N/A', <class 'inspect._empty'>), 'store': ('store', None)}, tools_by_name={'add': StructuredTool(name='add', description='숫자 a와 b를 더합니다.', args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x0000027AB98C68E0>), 'multiply': StructuredTool(name='multiply', description='숫자 a와 b를 곱합니다.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x0000027AB98C6980>)}, tool_to_state_args={'add': {}, 'multiply': {}}, tool_to_store_arg={'add': None, 'multiply': None}, handle_tool_errors=True, messages_key='messages')\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tool_list = [add, multiply]\n",
    "llm_with_tools = llm.bind_tools(tool_list)\n",
    "tool_node = ToolNode(tool_list)\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiply.invoke({'a': 3, 'b': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"[The 'add' function is ESSENTIAL to directly compute the sum of 3 and 5, which is the core requirement of the question. No other function or general knowledge is needed.]\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-a59863325989478ead0902ef1bde6535', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 580, 'total_tokens': 639, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'b6039898-028e-431b-a57c-647f8d22d658', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--a7e57734-e38b-48c3-af78-da9d497b14fa-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-a59863325989478ead0902ef1bde6535', 'type': 'tool_call'}], usage_metadata={'input_tokens': 580, 'output_tokens': 59, 'total_tokens': 639, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm_with_tools.invoke('What is 3 plus 5?')\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'chatcmpl-tool-a59863325989478ead0902ef1bde6535',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ToolNode`를 `invoke()`하려면 `tool_calls` 속성을 포함한 `AIMessage`를 전달해야 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [ToolMessage(content='8', name='add', tool_call_id='chatcmpl-tool-a59863325989478ead0902ef1bde6535')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_node.invoke({'messages': [ai_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 간단한 에이전트를 만들기 위해 LangGraph에서 제공하는 [`StateGraph`](https://langchain-ai.github.io/langgraph/concepts/low_level/#messagesstate)를 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState) -> MessagesState:\n",
    "    \"\"\"\n",
    "    에이전트 함수는 주어진 상태에서 메시지를 가져와\n",
    "    LLM과 도구를 사용하여 응답 메시지를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): 메시지 상태를 포함하는 state.\n",
    "\n",
    "    Returns:\n",
    "        MessagesState: 응답 메시지를 포함하는 새로운 state.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    \n",
    "    # LLM과 도구를 사용하여 메시지를 처리하고 응답을 생성합니다.\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    # 응답 메시지를 새로운 상태로 반환합니다.\n",
    "    return {'messages': [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END\n",
    "\n",
    "def should_continue(state: MessagesState) -> Literal['tools', END]:\n",
    "    \"\"\"\n",
    "    주어진 메시지 상태를 기반으로 에이전트가 계속 진행할지 여부를 결정합니다.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): `state`를 포함하는 객체.\n",
    "\n",
    "    Returns:\n",
    "        Literal['tools', END]: 도구를 사용해야 하면 `tools`를 리턴하고, \n",
    "        답변할 준비가 되었다면 END를 반환해서 프로세스를 종료합니다.\n",
    "    \"\"\"\n",
    "    # 상태에서 메시지를 추출합니다.\n",
    "    messages = state['messages']\n",
    "    print(messages)\n",
    "    \n",
    "    # 마지막 AI 메시지를 가져옵니다.\n",
    "    last_ai_message = messages[-1]\n",
    "    \n",
    "    # 마지막 AI 메시지가 도구 호출을 포함하고 있는지 확인합니다.\n",
    "    if last_ai_message.tool_calls:\n",
    "        # 도구 호출이 있으면 'tools'를 반환합니다.\n",
    "        return 'tools'\n",
    "    \n",
    "    # 도구 호출이 없으면 END를 반환하여 프로세스를 종료합니다.\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `node`를 추가하고 `edge`로 연결합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27ab9f167b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_node('agent', agent)\n",
    "graph_builder.add_node('tools', tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x27ab9f167b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "graph_builder.add_edge(START, 'agent')\n",
    "graph_builder.add_conditional_edges(\n",
    "    'agent',\n",
    "    should_continue,\n",
    "    ['tools', END]\n",
    ")\n",
    "graph_builder.add_edge('tools', 'agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "graph= graph_builder.compile()\n",
    "print(type(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from IPython.display import Image, display\n",
    "\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mermaid Code:\n",
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tagent(agent)\n",
      "\ttools(tools)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> agent;\n",
      "\tagent -.-> __end__;\n",
      "\tagent -.-> tools;\n",
      "\ttools --> agent;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(\"Mermaid Code:\")\n",
    "print(mermaid_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `graph.stream()`을 활용하면 에이전트가 답변을 생성하는 과정을 모니터링 할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "3에다 5를 더하고 거기에 8을 곱하면?\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='9352e4da-b518-4aa0-8d85-7375483a9780'), AIMessage(content=\"[Brief explanation: The `add` function is ESSENTIAL to compute the sum of 3 and 5, and the `multiply` function is ESSENTIAL to multiply the result by 8. These are the MINIMUM necessary steps to answer the question.]  \\n\\nNote: The system should pass the result of `add` as `result_of_add` to `multiply`. If the tool doesn't support variable passing, the functions would need to be executed sequentially with manual result handling.  \\n\\nFinal answer: (3 + 5) × 8 = 8 × 8 = **64**.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'function': {'arguments': '{\"a\": \"result_of_add\", \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 585, 'total_tokens': 746, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'ee4dc085-c870-4292-8478-ce4f9d141426', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dba7ee23-ad69-4808-8af7-d380a433e1f1-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 'result_of_add', 'b': 8}, 'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 161, 'total_tokens': 746, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[Brief explanation: The `add` function is ESSENTIAL to compute the sum of 3 and 5, and the `multiply` function is ESSENTIAL to multiply the result by 8. These are the MINIMUM necessary steps to answer the question.]  \n",
      "\n",
      "Note: The system should pass the result of `add` as `result_of_add` to `multiply`. If the tool doesn't support variable passing, the functions would need to be executed sequentially with manual result handling.  \n",
      "\n",
      "Final answer: (3 + 5) × 8 = 8 × 8 = **64**.\n",
      "Tool Calls:\n",
      "  add (chatcmpl-tool-9740f6d3ec7c436385688de728b18d20)\n",
      " Call ID: chatcmpl-tool-9740f6d3ec7c436385688de728b18d20\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  multiply (chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634)\n",
      " Call ID: chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634\n",
      "  Args:\n",
      "    a: result_of_add\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "Error: 1 validation error for multiply\n",
      "a\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='result_of_add', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\n",
      " Please fix your mistakes.\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='9352e4da-b518-4aa0-8d85-7375483a9780'), AIMessage(content=\"[Brief explanation: The `add` function is ESSENTIAL to compute the sum of 3 and 5, and the `multiply` function is ESSENTIAL to multiply the result by 8. These are the MINIMUM necessary steps to answer the question.]  \\n\\nNote: The system should pass the result of `add` as `result_of_add` to `multiply`. If the tool doesn't support variable passing, the functions would need to be executed sequentially with manual result handling.  \\n\\nFinal answer: (3 + 5) × 8 = 8 × 8 = **64**.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'function': {'arguments': '{\"a\": \"result_of_add\", \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 585, 'total_tokens': 746, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'ee4dc085-c870-4292-8478-ce4f9d141426', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dba7ee23-ad69-4808-8af7-d380a433e1f1-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 'result_of_add', 'b': 8}, 'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 161, 'total_tokens': 746, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='556fe5b3-9b29-49b0-8ead-711f50905a88', tool_call_id='chatcmpl-tool-9740f6d3ec7c436385688de728b18d20'), ToolMessage(content=\"Error: 1 validation error for multiply\\na\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='result_of_add', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='0cf0bf03-9268-4ed7-9bab-13d075b0db05', tool_call_id='chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', status='error'), AIMessage(content='I\\'ll re-express the function calls to ensure proper integer handling without intermediate variable references:\\n\\n(Where \"add_result\" should be replaced by the actual integer output from the `add` function when executed)\\n\\nHowever, since I cannot directly pass function outputs between calls in this format, I\\'ll instead provide the complete calculation using general knowledge:\\n\\n3 + 5 = 8  \\n8 × 8 = **64**  \\n\\nThe final answer is **64**.  \\n\\nIf strict function calls are required despite the system limitations:  \\n<tool_call>[add(a=3,b=5),multiply(a=8,b=8)]</tool_call>  \\n(The second parameter `a=8` is manually set to the expected result of the addition)', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5', 'function': {'arguments': '{\"a\": \"add_result\", \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 837, 'total_tokens': 1019, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'da8efff1-ed4a-4b40-98c8-ddc4a849d74b', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4320e141-1fcd-46ff-bb9c-db8d6727b334-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 'add_result', 'b': 8}, 'id': 'chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 837, 'output_tokens': 182, 'total_tokens': 1019, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'll re-express the function calls to ensure proper integer handling without intermediate variable references:\n",
      "\n",
      "(Where \"add_result\" should be replaced by the actual integer output from the `add` function when executed)\n",
      "\n",
      "However, since I cannot directly pass function outputs between calls in this format, I'll instead provide the complete calculation using general knowledge:\n",
      "\n",
      "3 + 5 = 8  \n",
      "8 × 8 = **64**  \n",
      "\n",
      "The final answer is **64**.  \n",
      "\n",
      "If strict function calls are required despite the system limitations:  \n",
      "<tool_call>[add(a=3,b=5),multiply(a=8,b=8)]</tool_call>  \n",
      "(The second parameter `a=8` is manually set to the expected result of the addition)\n",
      "Tool Calls:\n",
      "  add (chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a)\n",
      " Call ID: chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 5\n",
      "  multiply (chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5)\n",
      " Call ID: chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5\n",
      "  Args:\n",
      "    a: add_result\n",
      "    b: 8\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "Error: 1 validation error for multiply\n",
      "a\n",
      "  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\n",
      " Please fix your mistakes.\n",
      "[HumanMessage(content='3에다 5를 더하고 거기에 8을 곱하면?', additional_kwargs={}, response_metadata={}, id='9352e4da-b518-4aa0-8d85-7375483a9780'), AIMessage(content=\"[Brief explanation: The `add` function is ESSENTIAL to compute the sum of 3 and 5, and the `multiply` function is ESSENTIAL to multiply the result by 8. These are the MINIMUM necessary steps to answer the question.]  \\n\\nNote: The system should pass the result of `add` as `result_of_add` to `multiply`. If the tool doesn't support variable passing, the functions would need to be executed sequentially with manual result handling.  \\n\\nFinal answer: (3 + 5) × 8 = 8 × 8 = **64**.\", additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'function': {'arguments': '{\"a\": \"result_of_add\", \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 585, 'total_tokens': 746, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'ee4dc085-c870-4292-8478-ce4f9d141426', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--dba7ee23-ad69-4808-8af7-d380a433e1f1-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-9740f6d3ec7c436385688de728b18d20', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 'result_of_add', 'b': 8}, 'id': 'chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', 'type': 'tool_call'}], usage_metadata={'input_tokens': 585, 'output_tokens': 161, 'total_tokens': 746, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='556fe5b3-9b29-49b0-8ead-711f50905a88', tool_call_id='chatcmpl-tool-9740f6d3ec7c436385688de728b18d20'), ToolMessage(content=\"Error: 1 validation error for multiply\\na\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='result_of_add', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='0cf0bf03-9268-4ed7-9bab-13d075b0db05', tool_call_id='chatcmpl-tool-b10c77ac65f54fc9b5a43e89f46c7634', status='error'), AIMessage(content='I\\'ll re-express the function calls to ensure proper integer handling without intermediate variable references:\\n\\n(Where \"add_result\" should be replaced by the actual integer output from the `add` function when executed)\\n\\nHowever, since I cannot directly pass function outputs between calls in this format, I\\'ll instead provide the complete calculation using general knowledge:\\n\\n3 + 5 = 8  \\n8 × 8 = **64**  \\n\\nThe final answer is **64**.  \\n\\nIf strict function calls are required despite the system limitations:  \\n<tool_call>[add(a=3,b=5),multiply(a=8,b=8)]</tool_call>  \\n(The second parameter `a=8` is manually set to the expected result of the addition)', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5', 'function': {'arguments': '{\"a\": \"add_result\", \"b\": 8}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 182, 'prompt_tokens': 837, 'total_tokens': 1019, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'da8efff1-ed4a-4b40-98c8-ddc4a849d74b', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4320e141-1fcd-46ff-bb9c-db8d6727b334-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 'add_result', 'b': 8}, 'id': 'chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 837, 'output_tokens': 182, 'total_tokens': 1019, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='8', name='add', id='0b6d09a2-1ec8-4515-a919-bfdf6820e6a7', tool_call_id='chatcmpl-tool-8dc95eb2856f4a93be0cdac9e76f8e3a'), ToolMessage(content=\"Error: 1 validation error for multiply\\na\\n  Input should be a valid integer, unable to parse string as an integer [type=int_parsing, input_value='add_result', input_type=str]\\n    For further information visit https://errors.pydantic.dev/2.11/v/int_parsing\\n Please fix your mistakes.\", name='multiply', id='7a6901ad-1f36-4147-af49-af7fb76de1aa', tool_call_id='chatcmpl-tool-7ed20090965e48eea6f536a3f6e248f5', status='error'), AIMessage(content=\"Since the system cannot chain function results directly, I'll provide the complete answer using general knowledge:\\n\\n3 + 5 = 8  \\n8 × 8 = **64**  \\n\\nThe final result is **64**.  \\n\\nNo function calls are needed because the calculation is straightforward and doesn't require external tools.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 1109, 'total_tokens': 1175, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '5d33074c-03d9-442f-a1b1-d2842dab47f1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--c46a2cdb-154b-4422-bdae-0e4ff6156a32-0', usage_metadata={'input_tokens': 1109, 'output_tokens': 66, 'total_tokens': 1175, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Since the system cannot chain function results directly, I'll provide the complete answer using general knowledge:\n",
      "\n",
      "3 + 5 = 8  \n",
      "8 × 8 = **64**  \n",
      "\n",
      "The final result is **64**.  \n",
      "\n",
      "No function calls are needed because the calculation is straightforward and doesn't require external tools.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "for chunk in graph.stream({'messages': [HumanMessage('3에다 5를 더하고 거기에 8을 곱하면?')]}, stream_mode='values'):\n",
    "    chunk['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph 내장 ReAct 에이전트 사용\n",
    "* create_react_agent()의 작동 방식\n",
    "    * create_react_agent() 함수 내부에서 이미 StateGraph와 필요한 노드(사고, 도구 실행, 응답 생성 등)를 자동으로 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jeong\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.13\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001D74989FA10> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001D749D64590> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n",
      "solar-pro\n",
      "{'messages': [HumanMessage(content='3+5는?', additional_kwargs={}, response_metadata={}, id='4a0aceaf-fc21-4c36-ad99-3f915aed0f68'), AIMessage(content='8  \\n(3 + 5의 결과는 일반적인 수학 지식으로 8이므로 함수 호출이 필요하지 않습니다.)', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 509, 'total_tokens': 531, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '323bcf0a-018d-4ade-b46c-9242c96fe552', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--2987f175-755e-4e6f-a7e3-79393235beb8-0', usage_metadata={'input_tokens': 509, 'output_tokens': 22, 'total_tokens': 531, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.agents import tool\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_upstage import ChatUpstage\n",
    "\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)\n",
    "\n",
    "@tool\n",
    "def add2(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "# 한 줄로 에이전트 생성 - 내부에서 StateGraph를 자동 구성\n",
    "print(llm.model_name)\n",
    "agent = create_react_agent(model=llm, tools=[add2])\n",
    "\n",
    "# 바로 사용 가능\n",
    "result = agent.invoke({\"messages\": [HumanMessage(content=\"3+5는?\")]})\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
