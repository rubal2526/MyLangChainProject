{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_X\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 인터넷의 방대한 텍스트에서 다음 단어를 맞히는 방식으로 스스로 패턴을 학습합니다.  \\n'\n",
      " '학습 중에는 사람이 정답을 주지 않고, 모델이 문맥을 활용해 스스로 단어의 관계를 파악합니다.  \\n'\n",
      " '이렇게 얻은 지식을 바탕으로, 새로운 질문에 대해 자연스럽고 유착한 응답을 생성합니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    #model=\"openai/gpt-oss-120b\",\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('ChatGPT 모델의 학습 원리는 다음과 같습니다.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT는 대규모 언어 모델로, 수십억 개의 매개변수를 가지고 있으며, 이를 통해 자연어 처리 작업을 수행합니다. 이 모델은 '\n",
      " '대규모의 텍스트 데이터를 학습하여 언어의 패턴과 구조를 이해하며, 이를 바탕으로 새로운 텍스트를 생성하거나 질문에 답변할 수 있습니다. '\n",
      " 'ChatGPT의 학습에는 감독 학습과 강화 학습이 사용되며, 이를 통해 모델은 사용자 입력에 대한 적절한 응답을 생성하는 능력을 '\n",
      " '배웁니다.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT 모델의 장점은 다음과 같습니다.\\n'\n",
      " '\\n'\n",
      " '*   자연어 이해 능력: ChatGPT는 자연어 처리에 특화되어 있어, 사용자가 입력한 자연어를 이해하고 이에 적절한 응답을 제공할 수 '\n",
      " '있습니다.\\n'\n",
      " '*   지식 정보 제공: ChatGPT는 방대한 양의 데이터를 학습했기 때문에, 사용자에게 다양한 주제에 대한 지식 정보를 제공할 수 '\n",
      " '있습니다.\\n'\n",
      " '*   대화 관리: ChatGPT는 대화의 흐름을 관리하고, 상황에 맞는 응답을 제공할 수 있습니다.\\n'\n",
      " '\\n'\n",
      " 'ChatGPT 모델과 비슷한 AI 모델은 다음과 같습니다.\\n'\n",
      " '\\n'\n",
      " '*   **메타 리자**: 메타 리자는 메타에서 개발한 대규모 언어 모델입니다. ChatGPT와 마찬가지로 자연어 이해 및 생성 능력에 '\n",
      " '중점을 두고 있습니다.\\n'\n",
      " '*   **구글 바드**: 구글 바드는 구글이 개발한 대규모 언어 모델입니다. ChatGPT와 마찬가지로 자연어 이해 및 생성 능력에 '\n",
      " '중점을 두고 있습니다.\\n'\n",
      " '*   **마이크로소프트 빙 AI**: 마이크로소프트 빙 AI는 마이크로소프트가 개발한 대규모 언어 모델입니다. ChatGPT와 '\n",
      " '마찬가지로 자연어 이해 및 생성 능력에 중점을 두고 있습니다.\\n'\n",
      " '\\n'\n",
      " '이러한 모델들은 모두 대규모 언어 모델로, 자연어 이해 및 생성 능력에 중점을 두고 있습니다. 하지만 각각의 모델은 고유한 특징과 장점을 '\n",
      " '가지고 있습니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "#combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"한국어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"한국어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.', 'claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('GPT-4는 방대한 텍스트 데이터를 통해 다음 단어를 예측하는 ‘예측 학습’ 방식으로 훈련됩니다.  \\n'\n",
      " '학습 과정에서 인공 신경망이 문맥을 파악해 단어 간 확률 분포를 조정하며, 인간의 피드백(RLHF)으로 답의 품질을 미세 '\n",
      " '조정합니다.  \\n'\n",
      " '결국 통계적 패턴 기반 생성이지만, 대규모 데이터와 강화학습이 결합되어 인간 수준의 자연스러운 대화 능력을 갖추게 됩니다.')\n",
      "<class 'str'> Gemma 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Gemma는 Google의 Transformer 아키텍처를 기반으로 한 언어 모델로, 대규모 텍스트 데이터에서 다음 토큰을 예측하는 '\n",
      " '방식으로 학습됩니다.  \\n'\n",
      " '모델은 인코더-디코더 구조를 사용하며, 주어진 입력 문맥에서 가장 적절한 단어를 예측하도록 최적화됩니다.  \\n'\n",
      " '학습 과정에서는 마스크드 언어 모델링(MLM)과 같은 자기 지도 학습 기법을 활용하여 패턴을 스스로 학습합니다.  \\n'\n",
      " '이를 통해 Gemma는 다양한 자연어 처리 작업에 대해 사전 학습된 지식을 활용할 수 있습니다.')\n",
      "<class 'str'> claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude는 대규모 언어 모델로, 방대한 텍스트 데이터에서 다음 토큰을 예측하도록 학습됩니다.  \\n'\n",
      " '인간 피드백 강화학습(RLHF)을 통해 유해한 답변은 줄이고 도움이 되는 답변은 강화합니다.  \\n'\n",
      " '지식은 학습 시점에서 고정되며, 실시간 인터넷 검색은 하지 않습니다.  \\n'\n",
      " '사용자와의 대화 맥락을 바탕으로 적절한 응답을 생성합니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 3},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 4},\n",
    "    {\"model_name\": \"claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "ChatGPT는 “GPT(Generative Pre-trained Transformer)”라는 대규모 언어 모델을 기반으로 만들어졌습니다.  \n",
      "GPT가 “말을 잘하게” 되는 과정은 크게 3단계로 나눌 수 있으며, 각 단계의 목표와 학습 방식이 다릅니다.\n",
      "\n",
      "1. Pre-training(사전 학습) – “많은 글을 읽고 통계적 패턴을 기억”  \n",
      "   • 목표: 다음 토큰(≈단어·부분 단어)을 맞추는 ‘자기 회귀’ 문제를 푸는 것.  \n",
      "     예) “The weather is nice ___” → “today”일 확률이 높다는 사실을 학습.  \n",
      "   • 데이터: 웹, 책, 위키, 논문 등 방대한 무표정 텍스트.  \n",
      "   • 모델 구조:  \n",
      "     – Transformer 디코더(마스크드 셀프 어텐션)  \n",
      "     – 96층, 96-head, 임베딩 차원 12,288(d=12,288) 등 초거대 파라미터(175B).  \n",
      "   • 최적화:  \n",
      "     – Cross-entropy 손실 ↓, Adam, 1×10⁻⁴ lr, cosine 스케줄, bfloat16 혼합 정밀도.  \n",
      "     – 수청만 달러 GPU 시간이 소요.  \n",
      "   • 결과:  \n",
      "     – ‘확률 시뮬레이터’가 됨. 주어진 앞 문맥 뒤에 올 토큰의 분포 pθ(tk|t<k)를 출력.  \n",
      "     – 질문-답, 번역, 요약 등 다운스트림 임무에 대한 ‘지식’은 있지만 ‘지시 따르기’ 능력은 거의 없음.\n",
      "\n",
      "2. Supervised Fine-Tuning(SFT, 지도 미세 조정) – “지시문-응답 쌍을 보고 형식을 익힌다”  \n",
      "   • 데이터: 1~2만 개의 고품질 (지시문, 이상적 응답) 쌍.  \n",
      "   • 목표: 지시문이 주어졌을 때 인간이 선호하는 응답을 생성하도록 조정.  \n",
      "   • 최적화:  \n",
      "     – 동일한 ‘다음 토큰 예측’ 손실, 하지만 지금은 ‘지시+응답’ 전체를 최대 우도로 학습.  \n",
      "     – 보통 1~3 epoch, lr 1×10⁻⁵~5×10⁻⁶.  \n",
      "   • 결과:  \n",
      "     – 형식(지시→응답)은 익히지만, 여전히 ‘잘못된 답·유해한 답’ 가능성이 큼.\n",
      "\n",
      "3. Reinforcement Learning from Human Feedback(RLHF) – “사람의 선호를 보상讯호로 삼아 안전·유용성 향상”  \n",
      "   3-A. 보상 모델(RM) 만들기  \n",
      "       – 같은 질문에 대해 두 개의 응답을 모델이 생성 → 인간이 ‘어느 쪽이 더 나은가’ 라벨.  \n",
      "       – RM은 Bradley-Terry 모델로 학습:  \n",
      "         RM(x, y) = rθ(x, y)  \n",
      "         P(y₁≻y₂) = σ(rθ(x,y₁) − rθ(x,y₂))  \n",
      "       – 손실: −log σ(rθ(x,y_w) − rθ(x,y_l)), 여기서 y_w, y_l는 각각 선호/비선호 응답.  \n",
      "   3-B. 정책(주 모델) 최적화  \n",
      "       – PPO(Proximal Policy Optimization) 사용.  \n",
      "       – 목적함수:  \n",
      "         L^{RL} = 𝔼[ rθ(x,y) − β log(πRL/πSFT) ]  \n",
      "         여기서 KL 패널티(β)는 ‘SFT 모델과 너무 멀어지지 말라’는 제약.  \n",
      "       – 몇천 단계 수행하며 RM의 점수 ↑, 실제 인간 평가 점수 ↑.\n",
      "\n",
      "4. (선택) Rule-based 보상, Constitutional AI, RLAIF 등으로 반복 개선  \n",
      "   – 잘못된 답, 유해 답 발생률 추가 ↓.\n",
      "\n",
      "요약하면  \n",
      "1) 방대한 텍스트로 ‘언어 확률’을 배우고,  \n",
      "2) 지시-응답 예시로 ‘형식’을 배우며,  \n",
      "3) 사람의 선호 피드백으로 ‘정답률·안전성·도움성’을 극대화하는 것이 ChatGPT의 학습 원리입니다.\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍이 정말 좋아.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "태양계에는 8개의 행성이 있습니다. \n",
      "\n",
      "1.  수성: 태양과 가장 가까운 행성으로, 표면이 암석으로 구성되어 있고 극도로 높은 온도와 낮은 온도가 반복됩니다.\n",
      "2.  금성: 태양계에서 두 번째로 가까운 행성으로, 두꺼운 대기로 인해 극심한 온실 효과가 발생하여 매우 뜨겁습니다.\n",
      "3.  지구: 우리가 사는 행성으로, 물과 대기가 있어 생명체가 존재할 수 있습니다.\n",
      "4.  화성: 태양계에서 네 번째로 가까운 행성으로, 붉은색의 모래사막으로 덮여 있고 물과 생명체의 존재 가능성이 있습니다.\n",
      "5.  목성: 태양계에서 가장 큰 행성으로, 가스 거인이며 강력한 자기장과 수많은 위성을 가지고 있습니다.\n",
      "6.  토성: 태양계에서 두 번째로 큰 행성으로, 가스 거인이며 아름다운 고리를 가지고 있습니다.\n",
      "7.  천왕성: 태양계에서 일곱 번째로 가까운 행성으로, 가스 거인이며 자전축이 기울어져 있어 극단적인 기후 변화를 경험합니다.\n",
      "8.  해왕성: 태양계에서 가장 먼 행성으로, 가스 거인이며 강한 바람과 극적인 기후 변화를 가지고 있습니다.\n",
      "\n",
      "이러한 행성들은 각각 고유한 특징과 성질을 가지고 있으며, 태양계에서 중요한 역할을 합니다.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001F53DDFD450>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001F53DDFDF90>, root_client=<openai.OpenAI object at 0x000001F53DCF7390>, root_async_client=<openai.AsyncOpenAI object at 0x000001F53DDFDD10>, model_name='moonshotai/kimi-k2-instruct-0905', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "양자컴퓨터는 “동전이 앞면인지 뒷면인지”가 아니라 “앞면이면서 뒷면” 같은 특별한 상태(중첩)와, 두 동전이 서로 연결되어(얽힘) 한쪽을 보면 다른 쪽도 즉시 결정되는 성질을 이용해, 여러 계산을 한꺼번에 시도하는 “초고속 공책”이에요.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"양자컴퓨터를 간략히 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 좋은 질문이에요.  \n",
      "**태풍 발생**은 **여름~초가을(7~9월)**에 집중되긴 하지만, **가을에만 일어나는 대표적인 지구과학 현상**이라고 보기는 어렵습니다. 태풍은 계절보다는 **해수면 온도가 높은 시기**에 주로 발생하기 때문이죠.\n",
      "\n",
      "---\n",
      "\n",
      "### ✅ 가을에 주로 발생하는 **대표적인 지구과학 현상 3가지**:\n",
      "\n",
      "1. **시차 현상 (Equinox)** – **추분(秋分)**  \n",
      "   - 해가 **정활히 동쪽에서 떠서 정확히 서쪽으로 진다**는 현상  \n",
      "   - 낮과 밤의 길이가 **거의 같아지는 시기** (약 9월 23일경)\n",
      "\n",
      "2. **단풍 시작** – **기온 하강에 따른 식물의 생리적 반응**  \n",
      "   - **엽록소 분해 → 안토시아닌 합성** 등으로 인해 **잎이 빨간색·노란색으로 변색**  \n",
      "   - **기온이 낮고 일교차가 큰** 가을 날씨가 단풍에 **결정적 역할**을 함\n",
      "\n",
      "3. **고기압의 이동** – **시베리아 고기압의 확장**  \n",
      "   - **시베리아 고기압**이 남하하면서 **한반도에 차가운 건조한 공기**를 가져옴  \n",
      "   - 이로 인해 **기온이 급강하**하고 **가을비 → 맑은 날씨**로 전환되는 **가을 전선** 형성\n",
      "\n",
      "---\n",
      "\n",
      "### 요약\n",
      "태풍은 **여름~초가을**에 걸쳐 발생하지만, **가을에만 특별히 일어나는 현상**은 아닙니다.  \n",
      "가을에 **지구과학적으로 특별한 현상**은 **추분, 단풍, 시베리아 고기압의 확장**이 훨씬 더 대표적이에요.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season_name = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "1.  **추분과 추명** *   **날짜**: 매년 9월 23일, 추분은 낮과 밤의 길이가 같아지는 날 (평시 12시간) *   **설명은**: 추분은 태양이 적도 위를 지나가는 날로, 이 때 태평양 및 대서양에 있는 위성 천정각이 0도가 된다고 알려져 있습니다. (날씨가 추워지는 절기) *   **예상되는 영향**: 낮과 밤의 시간 변화에 따른 환경 조건 차이 때문일 수도 있지만, 식물에 대한 직접적인 영향은 적으로 추분에 의해 기상 재해 등 일교차가 크게 발생하지 말아야 할 듯 합니다. \n",
      "\n",
      "<!---->\n",
      "\n",
      "1.  **성층권 구름(스트라토스페릭 클라우드)** *   **날짜**: 가을에 추운 날씨가 시작되면서, 대기의 습도가 높아지는 때 *   **설명은**: 성층권 구름은 높은 고도에서 나타나는 구름입니다. *   **예상되는 영향**: 스트라토스페릭 클라우드라고 알려진 구름들은 대기의 열대권 대기 온도를 낮추는 효과가 있는 것으로 추정되고 있습니다. \n",
      "\n",
      "<!---->\n",
      "\n",
      "1.  **북극 저기압** *   **날짜**: 가을에 북극의 기온이 떨어지면서 약해지는 시점 *   **설명은**: 북극 저기압은 대기를 유지하는 온대적인 구조로, 약해지면 극지방의 고기압이 강해져 기상과 기후에 영향을 줍니다. *   **예상되는 영향**: 북극 저기압의 약화는 북극 지방에서 기상 패턴을 바꾸어 극한의 날씨를 나타낼 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season_name}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season_name\": lambda x : season_name}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season_name}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## 최근 환율 동향\n",
      "\n",
      "2024년 3월 말, 미국 달러화 대비 한국 원화 환율은 1달러 = 1,377.98원입니다. 최근 몇 개월 동안 한국 원화 가치는 다양한 요인으로 인해 변동하고 있습니다.\n",
      "\n",
      "## 경제 지표\n",
      "\n",
      "* 미국의 금리 인상: 미국의 연방준비제도(Fed)는 인플레이션 억제를 위해 금리를 인상하고 있습니다. 이는 달러화 가치를 상승시키고 있습니다.\n",
      "* 한국의 무역 수지: 한국의 무역 수지는 최근 수출 감소와 수입 증가로 인해 적자를 기록하고 있습니다. 이는 원화 가치를 하락시키고 있습니다.\n",
      "* 한국의 금리 인상: 한국은행은 인플레이션 억제를 위해 금리를 인상하고 있습니다. 이는 원화 가치를 상승시키고 있습니다.\n",
      "\n",
      "## 시장 전망\n",
      "\n",
      "* 달러화 가치: 미국 경제가 여전히 견조한 성장세를 보이고 있고, 인플레이션이 높은 수준을 유지하고 있기 때문에 달러화 가치는 당분간 높은 수준을 유지할 것으로 전망됩니다.\n",
      "* 원화 가치: 한국의 경제 성장세가 둔화되고 있고, 무역 수지 적자가 지속되고 있기 때문에 원화 가치는 당분간 약세를 보일 것으로 전망됩니다.\n",
      "\n",
      "## 환율 전망\n",
      "\n",
      "* 단기 전망: 달러화 가치가 높은 수준을 유지할 것으로 예상되기 때문에 원화 가치는 약세를 보일 것으로 전망됩니다. 따라서 환율은 1,380원 이상으로 상승할 가능성이 있습니다.\n",
      "* 장기 전망: 한국의 경제가 회복되고, 무역 수지가 개선되면 원화 가치는 상승할 것으로 전망됩니다. 따라서 환율은 1,300원 이하로 하락할 가능성이 있습니다.\n",
      "\n",
      "## 투자 전략\n",
      "\n",
      "* 수출 기업: 달러화 가치가 상승하면 수출 기업의 수익성이 개선될 수 있습니다. 따라서 수출 기업은 달러화 가치 상승에 대비하여 환 헷지를 고려할 수 있습니다.\n",
      "* 수입 기업: 달러화 가치가 상승하면 수입 기업의 비용이 증가할 수 있습니다. 따라서 수입 기업은 달러화 가치 상승에 대비하여 환 헷지를 고려할 수 있습니다.\n",
      "\n",
      "## 개인 투자자\n",
      "\n",
      "* 환율 변동 위험: 환율 변동은 투자자에게 위험을 초래할 수 있습니다. 따라서 투자자는 환율 변동을 주의 깊게 모니터링하고, 필요한 경우 환 헷지를 고려해야 합니다.\n",
      "* 투자 상품: 투자자는 환율 변동에 대비하여 외환 관련 투자 상품을 고려할 수 있습니다. 예를 들어, 달러화 표시 예금이나 달러화 연동 펀드 등에 투자할 수 있습니다.\n",
      "\n",
      "## 한국은행의 외환 정책\n",
      "\n",
      "* 한국은행은 환율 안정을 위해 외환 시장에 개입할 수 있습니다. 예를 들어, 달러화를 매입하여 원화 가치를 상승시키거나, 달러화를 매각하여 원화 가치를 하락시킬 수 있습니다.\n",
      "\n",
      "## 글로벌 경제 상황\n",
      "\n",
      "* 글로벌 경제 상황은 환율에 큰 영향을 미칩니다. 예를 들어, 글로벌 경제가 침체하면 안전 자산에 대한 수요가 증가하여 달러화 가치가 상승할 수 있습니다.\n",
      "\n",
      "## 무역 분쟁\n",
      "\n",
      "* 무역 분쟁은 환율에 큰 영향을 미칩니다. 예를 들어, 한국과 미국 간의 무역 분쟁이 심화하면 원화 가치가 하락할 수 있습니다.\n",
      "\n",
      "## 결론\n",
      "\n",
      "1달러 = 1,377.98원인 현재 환율은 다양한 요인에 의해 영향을 받고 있습니다. 미국 달러화 가치는 높은 수준을 유지할 것으로 예상되며, 한국 원화 가치는 약세를 보일 것으로 예상됩니다. 투자자는 환율 변동을 주의 깊게 모니터링하고, 필요한 경우 환 헷지를 고려해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
