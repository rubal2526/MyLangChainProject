{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "#### LangSmith 기본 예제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "##### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "##### 2) OpenAI 인증키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_X\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587fb89b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "##### LangSmith와 LangChain을 활용한 기본 로깅 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 [AI 답변]:\n",
      "LangGraph와 LangChain은 모두 언어 모델을 활용하여 애플리케이션을 구축하기 위한 프레임워크이지만, 두 프레임워크는 서로 다른 디자인 철학과 사용 사례에 중점을 둡니다.\n",
      "\n",
      "LangChain은 언어 모델을 사용하여 애플리케이션을 구축하기 위한 오픈 소스 프레임워크입니다. 대규모 언어 모델(LLM)을 통합하고, 다른 데이터 소스에 연결하고, 구조화된 출력으로 응답을 보강하는 기능을 제공합니다. LangChain은 에이전트를 구축하기 위한 프레임워크로, 에이전트에 자율성과 결정론적 행동을 제공하여 예측 가능하고 제어된 방식으로 작동할 수 있습니다.\n",
      "\n",
      "LangGraph는 LangChain을 기반으로 구축된 라이브러리로서, 다중 에이전트 워크플로를 더욱 쉽게 구축할 수 있도록 설계되었습니다. LangGraph를 사용하면 여러 에이전트 또는 작업 에이전트를 정의하고, 여러 하위 그래프를 정의하고, 에이전트 간의 제어를 정의하여 복잡한 워크플로를 작성할 수 있습니다.\n",
      "\n",
      "요약하면 LangChain은 에이전트를 구축하기 위한 프레임워크인 반면, LangGraph는 다중 에이전트 워크플로를 구축하기 위한 라이브러리입니다. LangChain은 더 일반적이고 다양한 애플리케이션에 사용할 수 있는 반면, LangGraph는 보다 구체적으로 설계되어 특정 사용 사례에 더 적합합니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langsmith import traceable\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "# LangSmith API Key 설정\n",
    "os.environ[\"LANGSMITH_TRACING\"] = os.getenv(\"LANGSMITH_TRACING\")  # LangSmith 활성화\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")  # API Key 불러오기\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")   # 프로젝트 이름 설정\n",
    "os.environ[\"LANGSMITH_ENDPOINT\"] = os.getenv(\"LANGSMITH_ENDPOINT\")   # EndPoint 설정\n",
    "\n",
    "# LLM 모델 설정 (OpenAI 사용)\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# LangSmith로 실행 추적\n",
    "@traceable(run_type=\"chain\", name=\"Simple_Chain\")\n",
    "def ask_question(question: str):\n",
    "\n",
    "    # 개별 메시지 템플릿 정의\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"당신은 유용한 AI 비서입니다.\"\n",
    "    )\n",
    "    user_message = HumanMessagePromptTemplate.from_template(\n",
    "        \"{question}\"\n",
    "    )\n",
    "\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([\n",
    "        system_message,\n",
    "        user_message,\n",
    "    ])\n",
    "    \n",
    "    messages = chat_prompt.format_messages(question=question)\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "# 테스트 실행\n",
    "question = \"LangGraph와 LangChain의 차이점은 무엇인가요?\"\n",
    "answer = ask_question(question)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"\\n🔹 [AI 답변]:\")\n",
    "print(answer)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
