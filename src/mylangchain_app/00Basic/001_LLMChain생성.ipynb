{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_X\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='인공지능 모델의 학습 원리는 \\'데이터를 통해 학습하여 미래의 예측이나 분류를 더 정확하게 하는 것\\'입니다. 예를 들어, 사진 속 고양이와 강아지를 구분하는 모델을 만든다고 가정해 봅시다.\\n\\n1. **데이터 수집**: 수많은 고양이와 강아지의 사진 데이터를 수집합니다.\\n2. **데이터 전처리**: 수집한 데이터를 컴퓨터가 처리할 수 있도록 숫자로 변환합니다. 예를 들어, 이미지를 픽셀 값으로 나타냅니다.\\n3. **모델 설정**: 고양이와 강아지를 구분할 수 있는 신경망 구조를 설계합니다. 예를 들어, 여러 층의 신경망을 쌓아 올린 \\'딥러닝\\' 모델을 사용할 수 있습니다.\\n4. **학습**: 수집한 데이터를 모델에 입력하고, 모델이 예측한 결과와 실제 레이블(고양이 또는 강아지)을 비교하여 오류를 계산합니다. 이 오류를 최소화하기 위해 모델의 가중치를 조정하는 과정을 반복합니다. 예를 들어, 모델이 사진 속 동물을 \\'고양이\\'로 예측했는데 실제는 \\'강아지\\'라면, 모델은 \"다음에는 더 정확하게 구분해야지\"하고 가중치를 조정합니다.\\n5. **평가**: 학습이 완료된 후, 새로운 데이터를 모델에 입력하여 성능을 평가합니다. 예를 들어, 새로운 사진 속 동물을 얼마나 정확하게 고양이와 강아지로 구분하는지 확인합니다.\\n\\n이 과정을 통해 모델은 데이터를 통해 학습하여 미래의 예측이나 분류를 더 정확하게 하게 됩니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 314, 'prompt_tokens': 24, 'total_tokens': 338, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.763097725, 'prompt_time': 0.000644399, 'completion_time': 0.78814849, 'total_time': 0.788792889}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'id': 'chatcmpl-993c07b3-5f53-43b0-8b4e-cc7e028e61e6', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--323501f0-1546-4e39-9fc0-4abf44b542fd-0' usage_metadata={'input_tokens': 24, 'output_tokens': 314, 'total_tokens': 338, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 '데이터를 통해 학습하여 미래의 예측이나 분류를 더 정확하게 하는 것'입니다. 예를 들어, 사진 속 고양이와 강아지를 구분하는 모델을 만든다고 가정해 봅시다.\n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진 데이터를 수집합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 컴퓨터가 처리할 수 있도록 숫자로 변환합니다. 예를 들어, 이미지를 픽셀 값으로 나타냅니다.\n",
      "3. **모델 설정**: 고양이와 강아지를 구분할 수 있는 신경망 구조를 설계합니다. 예를 들어, 여러 층의 신경망을 쌓아 올린 '딥러닝' 모델을 사용할 수 있습니다.\n",
      "4. **학습**: 수집한 데이터를 모델에 입력하고, 모델이 예측한 결과와 실제 레이블(고양이 또는 강아지)을 비교하여 오류를 계산합니다. 이 오류를 최소화하기 위해 모델의 가중치를 조정하는 과정을 반복합니다. 예를 들어, 모델이 사진 속 동물을 '고양이'로 예측했는데 실제는 '강아지'라면, 모델은 \"다음에는 더 정확하게 구분해야지\"하고 가중치를 조정합니다.\n",
      "5. **평가**: 학습이 완료된 후, 새로운 데이터를 모델에 입력하여 성능을 평가합니다. 예를 들어, 새로운 사진 속 동물을 얼마나 정확하게 고양이와 강아지로 구분하는지 확인합니다.\n",
      "\n",
      "이 과정을 통해 모델은 데이터를 통해 학습하여 미래의 예측이나 분류를 더 정확하게 하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content=\"인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \\n\\n기본적으로 인공지능 모델은 주어진 데이터를 분석하고 학습하여, 그 데이터 속에 있는 패턴이나 관계를 발견하고, 이를 기반으로 미래의 데이터를 예측하거나 분류하는 것입니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 인공지능 모델에 학습시키려고 한다고 가정해 봅시다. \\n\\n1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다.\\n2. **데이터 전처리**: 각 사진들을 컴퓨터가 처리할 수 있는 숫자들의 배열로 변환합니다.\\n3. **모델 초기화**: 인공지능 모델을 초기화 합니다. 이는 모델에 고양이와 강아지에 대한 아무런 지식도 없다는 뜻입니다.\\n4. **학습**: 고양이 사진에는 '고양이'라는 레이블을, 강아지 사진에는 '강아지'라는 레이블을 달아서 모델에 입력합니다. 모델은 처음에 임의로 예측을 합니다. \\n5. **오차 계산**: 모델의 예측과 실제 레이블(고양이 또는 강아지) 간의 차이, 즉 오차를 계산합니다.\\n6. **모델 업데이트**: 이 오차를 줄이기 위해 모델의 내부 매개변수(가중치와 편향)를 조정합니다. 이 과정은 '역전파'라고 불리며, 모델이 조금 더 정확한 예측을 할 수 있도록 도와줍니다.\\n7. **반복**: 4~6번의 과정을 수많은 고양이와 강아지 사진들을 대상으로 반복합니다. 각 반복에서 모델은 조금씩 더 정확해집니다.\\n\\n이 과정을 통해 모델은 고양이와 강아지의 특징을 스스로 학습하게 됩니다. 예를 들어, 고양이는 귀가 뾰족하고 눈이 크며, 강아지는 귀가 쳐지고 혀가 긴 등입니다. \\n\\n결국, 인공지능 모델은 주어진 데이터 속에서 패턴을 발견하고, 이를 통해 새로운 사진이 주어졌을 때 그것이 고양이인지 강아지인지를 높은 확률로 맞추게 됩니다.\\n\\n이러한 학습 원리는 다양한 인공지능 모델들, 예를 들어 신경망, 결정 트리, 서포트 벡터 머신 등에 적용됩니다. 각 모델은 나름의 방식으로 데이터를 분석하고 학습하여 예측이나 분류 작업을 수행합니다.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 460, 'prompt_tokens': 36, 'total_tokens': 496, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.207048053, 'prompt_time': 0.000592628, 'completion_time': 1.127575725, 'total_time': 1.128168353}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_5d3e4e58e1', 'id': 'chatcmpl-6475d447-ee3b-4355-bec2-e2ed0cd1c860', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--96d564c5-8576-4247-ba01-93d3f425a1d6-0' usage_metadata={'input_tokens': 36, 'output_tokens': 460, 'total_tokens': 496, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 주어진 데이터를 분석하고 학습하여, 그 데이터 속에 있는 패턴이나 관계를 발견하고, 이를 기반으로 미래의 데이터를 예측하거나 분류하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 인공지능 모델에 학습시키려고 한다고 가정해 봅시다. \n",
      "\n",
      "1. **데이터 수집**: 수많은 고양이와 강아지의 사진을 수집합니다.\n",
      "2. **데이터 전처리**: 각 사진들을 컴퓨터가 처리할 수 있는 숫자들의 배열로 변환합니다.\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화 합니다. 이는 모델에 고양이와 강아지에 대한 아무런 지식도 없다는 뜻입니다.\n",
      "4. **학습**: 고양이 사진에는 '고양이'라는 레이블을, 강아지 사진에는 '강아지'라는 레이블을 달아서 모델에 입력합니다. 모델은 처음에 임의로 예측을 합니다. \n",
      "5. **오차 계산**: 모델의 예측과 실제 레이블(고양이 또는 강아지) 간의 차이, 즉 오차를 계산합니다.\n",
      "6. **모델 업데이트**: 이 오차를 줄이기 위해 모델의 내부 매개변수(가중치와 편향)를 조정합니다. 이 과정은 '역전파'라고 불리며, 모델이 조금 더 정확한 예측을 할 수 있도록 도와줍니다.\n",
      "7. **반복**: 4~6번의 과정을 수많은 고양이와 강아지 사진들을 대상으로 반복합니다. 각 반복에서 모델은 조금씩 더 정확해집니다.\n",
      "\n",
      "이 과정을 통해 모델은 고양이와 강아지의 특징을 스스로 학습하게 됩니다. 예를 들어, 고양이는 귀가 뾰족하고 눈이 크며, 강아지는 귀가 쳐지고 혀가 긴 등입니다. \n",
      "\n",
      "결국, 인공지능 모델은 주어진 데이터 속에서 패턴을 발견하고, 이를 통해 새로운 사진이 주어졌을 때 그것이 고양이인지 강아지인지를 높은 확률로 맞추게 됩니다.\n",
      "\n",
      "이러한 학습 원리는 다양한 인공지능 모델들, 예를 들어 신경망, 결정 트리, 서포트 벡터 머신 등에 적용됩니다. 각 모델은 나름의 방식으로 데이터를 분석하고 학습하여 예측이나 분류 작업을 수행합니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 배우고, 판단하고, 결정하는 능력을 키우는 과정이라고 생각하시면 됩니다.\n",
      "\n",
      "예를 들어, 어린아이가 고양이를 처음 봤을 때, 엄마가 \"이건 고양이야\"라고 말해줍니다. 처음에는 아이가 고양이를 알아보지 못하지만, 고양이를 여러 번 보고, 엄마가 고양이라고 말해줄 때마다 아이는 고양이의 특징들(예: 귀가 뾰족하고, 털이 보드라움)을 머릿속에 저장합니다.\n",
      "\n",
      "이렇게 고양이를 여러 번 보면서 특징들을 머릿속에 저장하는 과정이 인공지능 모델의 학습 원리와 비슷합니다.\n",
      "\n",
      "구체적으로는, 인공지능 모델이 데이터를 입력으로 받아서, 그 데이터의 특징들을 분석하고, 그 특징들을 기반으로 고양이인지 아닌지 판단하는 것입니다. 이 과정에서 모델은 데이터를 통해 배우고, 판단하는 능력을 키우게 됩니다.\n",
      "\n",
      "이를 위해 인공지능 모델은 다음과 같은 과정을 거칩니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습할 데이터를 수집합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 정제하고, 변환하여 모델이 학습하기 좋은 형태로 만듭니다.\n",
      "3. **모델 훈련**: 모델이 데이터를 입력으로 받아서, 출력(예: 고양이 또는 아니오)을 생성합니다.\n",
      "4. **오차 계산**: 모델의 출력과 실제 출력(예: 고양이)을 비교하여 오차를 계산합니다.\n",
      "5. **모델 업데이트**: 오차를 최소화하기 위해 모델의 가중치를 업데이트합니다.\n",
      "\n",
      "이 과정을 반복하면서 모델은 데이터를 통해 배우고, 판단하는 능력을 키우게 됩니다. 이렇게 학습된 모델은 새로운 데이터를 입력으로 받았을 때, 고양이인지 아닌지 판단할 수 있습니다.\n",
      "\n",
      "이처럼 인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사하며, 데이터를 통해 배우고, 판단하는 능력을 키우는 과정입니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다. 쉽게 설명하면, 인공지능 모델이 새로운 데이터를 학습할 때, 모델은 주어진 데이터를 보고 '이 데이터는 어떤 패턴이 있고, 이 패턴을 어떻게 분류하면 좋을까?'라고 스스로 생각합니다.\n",
      "\n",
      "이를 위해 인공지능 모델은 크게 세 가지 단계를 거칩니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델이 학습할 데이터를 수집합니다. 예를 들어, 고양이와 강아지의 사진을 모으는 것입니다.\n",
      "\n",
      "2. **학습**: 수집된 데이터를 바탕으로 모델이 스스로 학습합니다. 이 과정에서는 모델이 데이터의 패턴을 분석하고, 고양이 사진과 강아지 사진의 차이점을 스스로 찾아냅니다.\n",
      "\n",
      "3. **예측 및 평가**: 학습된 모델을 사용하여 새로운 사진을 보고 고양이인지 강아지인지를 예측합니다. 그리고 예측 결과의 정확도를 평가합니다.\n",
      "\n",
      "이러한 학습 과정을 통해 인공지능 모델은 점점 더 정확하게 고양이와 강아지를 구분할 수 있게 됩니다. 이처럼 인공지능 모델은 데이터를 통해 스스로 학습하고, 그 학습을 바탕으로 새로운 데이터에 대해 예측할 수 있는 능력을 키웁니다.\n",
      "\n",
      "예를 들어, 어린 아이에게 고양이와 강아지의 사진을 여러 장 보여주고, 고양이, 강아지라고 말해줍니다. 처음에는 아이가 고양이와 강아지를 구분하지 못하지만, 여러 장의 사진을 보고 듣다 보면, 아이는 고양이와 강아지의 특징을 스스로 찾아내고, 새로운 사진을 보여주었을 때 고양이인지 강아지인지를 말할 수 있게 됩니다. 인공지능 모델의 학습 원리도 이와 유사합니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약 ( 잘 동작하지 않는 코드 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "2022년에 개봉한 영화 '코다'입니다. \n",
      "\n",
      "'코다'라는 뜻은 '청각장애인의 자녀'를 의미합니다.\n",
      "\n",
      "CODA는 프랑스 영화 '가족의 탄생'을 리메이크한 작품으로, 청각장애인 가족의 이야기입니다.\n",
      "\n",
      "주인공 루비는 태어나면서부터 청력을 잃은 청각장애인 부모님과 농인 남동생을 둔 CODA입니다.\n",
      "\n",
      "루비는 유일하게 집에서 소리를 들을 수 있는 가족 구성원으로서 가족의 소통을 도와주는 역할을 합니다.\n",
      "\n",
      "그런데 루비는 본인이 음악에 관심이 있고 노래를 잘 부르는 등, 남들과는 조금 다른 삶을 꿈꾸고 있습니다.\n",
      "\n",
      "그러던 중 루비는 학교 선생님의 추천으로 음악 콩쿠르에 나가게 되는데, 이 영화는 루비가 가족과 자신의 삶에 대해 고민하고 성장하는 과정을 감동 있게 담아냈습니다.\n",
      "\n",
      "특히, 실제 청각장애인 배우들을 캐스팅하여 더욱 현실적이고 감동적인 연기를 선보였습니다.\n",
      "\n",
      "'코다'는 제 93회 아카데미 시상식에서 작품상, 감독상, 남우주연상, 각본상, 여우주연상 등 주요 5개 부문을 수상하는 쾌거를 이루었습니다.\n",
      "\n",
      "만약 당신이 감동적인 드라마 영화를 찾고 있다면 '코다'를 추천해 드립니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A36FCB9EB0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A36FCBA210>, root_client=<openai.OpenAI object at 0x000001A36FCB9C70>, root_async_client=<openai.AsyncOpenAI object at 0x000001A36FCB9FD0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001A36FCB9EB0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001A36FCBA210>, root_client=<openai.OpenAI object at 0x000001A36FCB9C70>, root_async_client=<openai.AsyncOpenAI object at 0x000001A36FCB9FD0>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " ## 노트북\n",
      "\n",
      "### 영화 정보\n",
      "\n",
      "*   **감독**: 닉 카사베츠(Nick Cassavetes)\n",
      "*   **캐스팅**: \n",
      "    *   **라이언 고슬링(Ryan Gosling) - 노아 칼훈 역**\n",
      "    *   **레이첼 매커즈(Rachel McAdams) - 앨리 해밀턴 역**\n",
      "    *   **제임스 가너(James Garner) - 노인 노아 역**\n",
      "    *   **지나 로우랜드스(Gena Rowlands) - 노인 앨리 역**\n",
      "\n",
      "### 줄거리\n",
      "\n",
      "1940년대 미국 노스 캐롤라이나를 배경으로 한 로맨틱 드라마 영화입니다. 노아 칼훈(라이언 고슬링)과 앨리 해밀턴(레이첼 매커즈)은 서로를 사랑하지만, 사회적 차이로 인해 헤어지게 됩니다. 노아는 앨리를 잊지 못하고, 그녀를 만나기 위해 노력합니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('**쇼생크 탈출(The Shawshank Redemption, 1994)**\\n'\n",
      " '\\n'\n",
      " '제목: 쇼생크 탈출(The Shawshank Redemption)  \\n'\n",
      " '감독: 프랭크 다라본트  \\n'\n",
      " '캐스팅: 팀 로빈스(앤디 듀프레인), 모건 프리먼(레드)  \\n'\n",
      " '줄거리: 은행원 앤디는 아내와 그녀의 정부를 살해했다는 누명을 쓴 채 쇼생크 교도소에 수감된다. 침착하고 조용한 그는 교도소의 부패와 '\n",
      " '폭력 속에서도 희망을 놓지 않고, 오랜 기간에 걸쳐 탈옥을 계획한다. 그 과정에서 20년형을 살고 있는 범인 레드와 깊은 우정을 쌓으며, '\n",
      " '‘희망’이란 단어의 진정한 의미를 일깨워 준다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cfea55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
