{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 36.261444558s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 36\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 34.039938128s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 34\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 29.812109789s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 29\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 21.595487831s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 21\n",
      "}\n",
      "].\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
      "* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 2\n",
      "Please retry in 5.370533459s. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.5-pro\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 2\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 5\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "네, AI 전문가로서 LangChain과 LangGraph에 대해 명확하고 깊이 있게 설명해 드리겠습니다.\n",
      "\n",
      "이 둘은 별개의 것이 아니라, **LangGraph가 LangChain을 기반으로 더 복잡한 작업을 수행하기 위해 만들어진 확장 라이브러리**라는 관계를 먼저 이해하는 것이 중요합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. LangChain (랭체인): LLM 애플리케이션을 위한 '레고 블록'\n",
      "\n",
      "**LangChain은 한마디로 '대규모 언어 모델(LLM)을 활용한 애플리케이션을 더 쉽고 강력하게 만들 수 있도록 도와주는 개발 프레임워크'입니다.**\n",
      "\n",
      "LLM 자체는 단순히 텍스트를 입력받아 텍스트를 생성하는 기능만 가지고 있습니다. 하지만 우리가 원하는 실제 애플리케이션(챗봇, 문서 요약, 코드 생성 등)을 만들려면 LLM 외에 여러 가지 구성 요소가 필요합니다. LangChain은 이 구성 요소들을 마치 **레고 블록처럼 조립**하여 복잡한 애플리케이션을 만들 수 있게 해줍니다.\n",
      "\n",
      "#### 핵심 개념 및 주요 구성 요소 (레고 블록들)\n",
      "\n",
      "*   **Models**: OpenAI의 GPT, Google의 Gemini 등 다양한 LLM 모델에 쉽게 연결할 수 있는 인터페이스입니다.\n",
      "*   **Prompts**: LLM에 전달할 지시문(프롬프트)을 효과적으로 관리하고, 변수를 넣어 동적으로 생성할 수 있는 템플릿 기능입니다.\n",
      "*   **Chains**: LangChain의 핵심 개념으로, **'LLM 호출'과 다른 구성 요소들을 순차적으로 연결한 작업 흐름**을 의미합니다. 예를 들어, `(1)사용자 질문 받기 -> (2)프롬프트 템플릿에 질문 삽입 -> (3)LLM에 질문 전달 -> (4)LLM 답변 받기 -> (5)답변 형식 파싱` 과 같은 일련의 과정을 하나의 '체인'으로 묶을 수 있습니다.\n",
      "*   **Indexes & Retrievers**: LLM이 학습하지 않은 외부 데이터(PDF, DB, 웹사이트 등)를 참조하여 답변을 생성하게 만드는 RAG(Retrieval-Augmented Generation) 패턴을 쉽게 구현하도록 돕습니다.\n",
      "*   **Memory**: 챗봇처럼 이전 대화 내용을 기억하게 하여 대화의 맥락을 유지하는 기능입니다.\n",
      "*   **Agents**: LLM이 단순히 답변만 생성하는 것을 넘어, **스스로 생각하고 판단하여 어떤 도구(Tool)를 사용할지 결정**하게 만드는 기능입니다. 예를 들어, \"오늘 파리 날씨를 알려주고 원화로 환산한 비행기표 값을 계산해줘\"라는 요청에 대해, Agent는 (1)날씨 검색 API를 호출하고, (2)환율 검색 API를 호출하고, (3)계산기 도구를 사용하여 최종 답변을 만들어냅니다.\n",
      "\n",
      "> **LangChain의 한계:**\n",
      "> Agent 기능이 강력하지만, 작업 흐름이 기본적으로 **선형적(Linear)인 '체인'**에 기반하기 때문에, 중간에 분기를 만들거나, 특정 조건에 따라 이전 단계로 돌아가는 **복잡한 순환(Cyclical) 로직**을 구현하기 어렵습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. LangGraph (랭그래프): 복잡한 Agent를 위한 '상태 기반의 순환 제어 시스템'\n",
      "\n",
      "**LangGraph는 LangChain의 한계를 극복하기 위해 등장했으며, '여러 단계와 주체(Agent)들이 상호작용하는 복잡하고 순환적인 워크플로우를 그래프(Graph) 형태로 구현할 수 있게 해주는 라이브러리'입니다.**\n",
      "\n",
      "LangChain의 '체인'이 한 방향으로만 흐르는 컨베이어 벨트라면, LangGraph는 여러 갈래의 길이 있고, 특정 조건에 따라 왔던 길을 되돌아갈 수도 있는 **'지능형 교통 관제 시스템' 또는 '플로우차트(Flowchart)'**와 같습니다.\n",
      "\n",
      "#### 핵심 개념 및 주요 구성 요소\n",
      "\n",
      "*   **State (상태)**: LangGraph의 가장 중요한 개념입니다. 모든 작업은 하나의 공유된 '상태 객체'를 중심으로 이루어지며, 각 단계를 거칠 때마다 이 상태가 계속 업데이트됩니다. 예를 들어, [처리할 질문, 중간 결과, 최종 답변] 등이 상태에 저장됩니다.\n",
      "*   **Nodes (노드)**: 그래프의 각 단계를 의미하며, 특정 작업을 수행하는 함수(Function)입니다. 노드는 LLM을 호출할 수도 있고, 특정 도구를 실행하거나, 간단한 데이터 처리 작업을 할 수도 있습니다. 각 노드는 입력으로 현재 '상태'를 받고, 작업 후 업데이트된 '상태'를 반환합니다.\n",
      "*   **Edges (엣지)**: 노드와 노드를 연결하는 '흐름'을 정의합니다.\n",
      "    *   **일반 엣지**: A 노드가 끝나면 항상 B 노드로 이동하도록 지정합니다.\n",
      "    *   **조건부 엣지 (Conditional Edges)**: LangGraph의 핵심 기능으로, **특정 노드의 결과에 따라 다음에 어떤 노드로 갈지 동적으로 결정**합니다. 이 기능 덕분에 **루프(Loop), 분기(Branch), 재시도(Retry)** 같은 복잡한 제어가 가능해집니다.\n",
      "\n",
      "#### LangGraph로 가능한 것들\n",
      "\n",
      "*   **다중 에이전트 협업**: '기획자 에이전트'가 아이디어를 내면, '개발자 에이전트'가 코드를 짜고, 'QA 에이전트'가 코드를 검토한 후, 문제가 있으면 다시 '개발자 에이전트'에게 수정을 요청하는 식의 순환적인 협업 시스템을 만들 수 있습니다.\n",
      "*   **Human-in-the-loop**: AI가 중요한 결정을 내리기 전에 사람에게 승인을 요청하고, 승인 결과에 따라 다음 작업을 진행하거나(Proceed), 작업을 수정하도록(Modify) 하는 워크플로우를 쉽게 구현할 수 있습니다.\n",
      "*   **자기 수정(Self-Correction)**: Agent가 생성한 결과물이 특정 기준에 미치지 못할 경우, 스스로 결과물을 평가하고 기준을 통과할 때까지 작업을 반복하도록(Loop) 만들 수 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 핵심적인 차이점 요약\n",
      "\n",
      "| 구분 | **LangChain** | **LangGraph** |\n",
      "| :--- | :--- | :--- |\n",
      "| **핵심 추상화** | **체인 (Chain)** | **그래프 (Graph)** |\n",
      "| **워크플로우** | **선형적 (Linear), 단방향** | **순환적 (Cyclical), 상태 기반** |\n",
      "| **제어 흐름** | 암시적, 순차적 | **명시적, 조건부 제어 가능 (루프, 분기)** |\n",
      "| **주요 사용 사례** | 간단한 RAG, 순차적 작업 자동화, 빠른 프로토타이핑 | **다중 에이전트 시스템, 복잡한 의사결정, Human-in-the-loop** |\n",
      "| **비유** | **레고 블록을 순서대로 쌓는 것** | **조건에 따라 움직이는 플로우차트를 그리는 것** |\n",
      "\n",
      "### 결론\n",
      "\n",
      "*   **LangChain**은 LLM 애플리케이션을 만들기 위한 **기본적인 재료와 도구(SDK)**를 제공하는 포괄적인 프레임워크입니다.\n",
      "*   **LangGraph**는 LangChain의 도구들을 사용하여, **더욱 복잡하고, 지능적이며, 제어 가능한 Agent 시스템**을 만들 수 있도록 도와주는 강력한 **실행 엔진(Execution Engine)**입니다.\n",
      "\n",
      "따라서 대부분의 LLM 애플리케이션 개발은 LangChain으로 시작하며, 여러 Agent가 상호작용하거나, 작업 흐름에 복잡한 조건부 로직이 필요할 때 LangGraph를 도입하여 시스템을 고도화하게 됩니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은(는) 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain과 LangGraph\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-1.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    #model=\"gemini-1.5-flash\",\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
